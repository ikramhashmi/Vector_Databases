{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "xgHZNcRSlQvH",
        "outputId": "05a45d57-b005-41f5-e734-54cc1e51b602"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.20)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.47)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.21 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.21)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.39)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.14)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.0.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.8.1)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.18)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.21->langchain-community) (0.3.7)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.21->langchain-community) (2.10.6)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.45->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.21->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.21->langchain-community) (2.27.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n",
            "Collecting pypdf\n",
            "  Downloading pypdf-5.4.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Downloading pypdf-5.4.0-py3-none-any.whl (302 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.3/302.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-5.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip -q install chromadb langchain langchain-groq tiktoken\n",
        "!pip install -U langchain-community\n",
        "!pip install pypdf\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show chromadb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "aBEH-MJVlY52",
        "outputId": "29457596-60ee-4509-c6d5-a25dcd423865"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: chromadb\n",
            "Version: 0.6.3\n",
            "Summary: Chroma.\n",
            "Home-page: https://github.com/chroma-core/chroma\n",
            "Author: \n",
            "Author-email: Jeff Huber <jeff@trychroma.com>, Anton Troynikov <anton@trychroma.com>\n",
            "License: \n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: bcrypt, build, chroma-hnswlib, fastapi, grpcio, httpx, importlib-resources, kubernetes, mmh3, numpy, onnxruntime, opentelemetry-api, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, opentelemetry-sdk, orjson, overrides, posthog, pydantic, pypika, PyYAML, rich, tenacity, tokenizers, tqdm, typer, typing_extensions, uvicorn\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['GROQ_API_KEY'] =  \"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\""
      ],
      "metadata": {
        "id": "DwvEDe9soQtv"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFDirectoryLoader"
      ],
      "metadata": {
        "id": "yS0sXW6hqGJp"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir pdfs"
      ],
      "metadata": {
        "id": "yyFDCaQaqXVf"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader=PyPDFDirectoryLoader(\"pdfs\")"
      ],
      "metadata": {
        "id": "LlSqrWxCqaIA"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=loader.load()"
      ],
      "metadata": {
        "id": "IHbIg5oRqdCv"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data[0].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "YPvCjOgkqu-8",
        "outputId": "3298e442-e039-48f5-e797-917a11753e0f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimizing AI Model Deployment for Open-Source Applications\n",
            "Google Summer of Code 2025 Proposal\n",
            "Project Title:\n",
            "Personal Information:\n",
            "Name:   Ikram Elahi Hashmi\n",
            "GitHub:  github.com/ikramhashmi\n",
            "LinkedIn: linkedin.com/in/ikram-hashmi\n",
            "Email:  ikramhashmi1111@gmail.com\n",
            "Project Summary:\n",
            "Your AI models in open-source applications is often challenging due to\n",
            "high computational costs, inefficiencies in model inference, and\n",
            "difficulties in scaling deployments. Many developers face obstacles when\n",
            "transitioning trained models from research environments to real-world\n",
            "production systems. This project aims to optimize AI model deployment\n",
            "by developing a lightweight, scalable, and resource-efficient framework.\n",
            "Leveraging my experience in machine learning, deep learning, and model\n",
            "deployment, as seen in my work on brain tumor detection, spam\n",
            "detection, and ML pipelines, I will implement techniques such as model\n",
            "quantization, pruning, and TensorFlow Lite optimization to enhance\n",
            "performance. Additionally, I will integrate Flask/FastAPI for API-based\n",
            "deployment, Docker for containerization, and CI/CD pipelines for\n",
            "automated updates. The final deliverables will include a fully optimized\n",
            "deployment framework, APIs for seamless integration, Dockerized setups,\n",
            "performance benchmarks, and comprehensive documentation. This\n",
            "project will significantly benefit the open-source community by making\n",
            "AI deployment more efficient, scalable, and accessible.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\n",
        "text_chunks=text_splitter.split_documents(data)\n",
        "print(text_chunks[1].page_content)\n",
        "print(f\"Total Chunks: {len(text_chunks)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tf6AGobSqxeg",
        "outputId": "9fdfa78b-b018-451a-b51b-91e0e91f07c3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "transitioning trained models from research environments to real-world\n",
            "production systems. This project aims to optimize AI model deployment\n",
            "by developing a lightweight, scalable, and resource-efficient framework.\n",
            "Leveraging my experience in machine learning, deep learning, and model\n",
            "deployment, as seen in my work on brain tumor detection, spam\n",
            "detection, and ML pipelines, I will implement techniques such as model\n",
            "quantization, pruning, and TensorFlow Lite optimization to enhance\n",
            "Total Chunks: 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "persist_directory = 'db'"
      ],
      "metadata": {
        "id": "xYWbFNPO1M6m"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings import SentenceTransformerEmbeddings\n",
        "embeddings = SentenceTransformerEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
        "\n",
        "vectordb = Chroma.from_documents(\n",
        "    documents=text_chunks,\n",
        "    embedding=embeddings,\n",
        "    persist_directory=persist_directory\n",
        ")"
      ],
      "metadata": {
        "id": "mPbDIr6n1HzJ"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectordb.persist()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gM_LqmIMzNZh",
        "outputId": "373e854c-9177-46e1-9857-b680fdea4289"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-36-d832e715b29a>:1: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
            "  vectordb.persist()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectordb = None"
      ],
      "metadata": {
        "id": "5FE5WIQH1o_Q"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectordb = Chroma(persist_directory=persist_directory,embedding_function=embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaPku9qE1s8r",
        "outputId": "d5a5c907-bb84-430d-9a67-765a980869b8"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-38-fa99698453ca>:1: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
            "  vectordb = Chroma(persist_directory=persist_directory,embedding_function=embeddings)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectordb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X87FaGhK1zlD",
        "outputId": "bc672d04-9b2b-4511-c245-e6ecf9ac56c7"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langchain_community.vectorstores.chroma.Chroma at 0x7b67a30e1c90>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectordb.as_retriever()"
      ],
      "metadata": {
        "id": "bLkareu210HT"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = retriever.get_relevant_documents(\"what is the email ofikram hashmi?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuwLn_Xx159L",
        "outputId": "5e30a879-5415-43ed-fc92-af24704c61cc"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-41-ae05741476d0>:1: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  docs = retriever.get_relevant_documents(\"what is the email ofikram hashmi?\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(docs[0].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "-xXYzW1g2BrR",
        "outputId": "ea8f3e67-d0db-4277-a4a3-20d9d55c0f2c"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimizing AI Model Deployment for Open-Source Applications\n",
            "Google Summer of Code 2025 Proposal\n",
            "Project Title:\n",
            "Personal Information:\n",
            "Name:   Ikram Elahi Hashmi\n",
            "GitHub:  github.com/ikramhashmi\n",
            "LinkedIn: linkedin.com/in/ikram-hashmi\n",
            "Email:  ikramhashmi1111@gmail.com\n",
            "Project Summary:\n",
            "Your AI models in open-source applications is often challenging due to\n",
            "high computational costs, inefficiencies in model inference, and\n",
            "difficulties in scaling deployments. Many developers face obstacles when\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectordb.as_retriever(search_kwargs={\"k\": 2})"
      ],
      "metadata": {
        "id": "oDtRthZs2LrS"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever.search_kwargs"
      ],
      "metadata": {
        "id": "Z3CXezI32PnZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs2 = retriever.get_relevant_documents(\"what is the email ofikram hashmi?\")"
      ],
      "metadata": {
        "id": "V7EyCJXx2SQE"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Sxgn-rcK2Z23",
        "outputId": "0953170e-eb5f-47cd-c625-a3396e018018"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'author': 'Social Work', 'creationdate': '2025-03-26T14:51:26+00:00', 'creator': 'Canva', 'keywords': 'DAGi1peDSjU,BAFimUWlNfY,0', 'moddate': '2025-03-26T14:51:24+00:00', 'page': 0, 'page_label': '1', 'producer': 'Canva', 'source': 'pdfs/Black White Simple Blank Resignation Letter.pdf', 'title': 'Black White Simple Blank Resignation Letter', 'total_pages': 3}, page_content='Optimizing AI Model Deployment for Open-Source Applications\\nGoogle Summer of Code 2025 Proposal\\nProject Title:\\nPersonal Information:\\nName:   Ikram Elahi Hashmi\\nGitHub:  github.com/ikramhashmi\\nLinkedIn: linkedin.com/in/ikram-hashmi\\nEmail:  ikramhashmi1111@gmail.com\\nProject Summary:\\nYour AI models in open-source applications is often challenging due to\\nhigh computational costs, inefficiencies in model inference, and\\ndifficulties in scaling deployments. Many developers face obstacles when'),\n",
              " Document(metadata={'author': 'Social Work', 'creationdate': '2025-03-26T14:51:26+00:00', 'creator': 'Canva', 'keywords': 'DAGi1peDSjU,BAFimUWlNfY,0', 'moddate': '2025-03-26T14:51:24+00:00', 'page': 0, 'page_label': '1', 'producer': 'Canva', 'source': 'pdfs/Black White Simple Blank Resignation Letter.pdf', 'title': 'Black White Simple Blank Resignation Letter', 'total_pages': 3}, page_content='Optimizing AI Model Deployment for Open-Source Applications\\nGoogle Summer of Code 2025 Proposal\\nProject Title:\\nPersonal Information:\\nName:   Ikram Elahi Hashmi\\nGitHub:  github.com/ikramhashmi\\nLinkedIn: linkedin.com/in/ikram-hashmi\\nEmail:  ikramhashmi1111@gmail.com\\nProject Summary:\\nYour AI models in open-source applications is often challenging due to\\nhigh computational costs, inefficiencies in model inference, and\\ndifficulties in scaling deployments. Many developers face obstacles when')]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain_groq import ChatGroq"
      ],
      "metadata": {
        "id": "p5ntUtMT2gje"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GROQ_API_KEY = os.environ.get('GROQ_API_KEY')"
      ],
      "metadata": {
        "id": "PB9cGSME3EeV"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGroq(api_key=GROQ_API_KEY, model_name=\"llama-3.3-70b-versatile\")"
      ],
      "metadata": {
        "id": "nH8xcAja2rZq"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_chain = RetrievalQA.from_chain_type(llm=llm,\n",
        "                                  chain_type=\"stuff\",\n",
        "                                  retriever=retriever,\n",
        "                                  return_source_documents=True)"
      ],
      "metadata": {
        "id": "Pu8BjP4s2kka"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_llm_response(llm_response):\n",
        "    print(llm_response['result'])\n",
        "    print('\\n\\nSources:')\n",
        "    for source in llm_response[\"source_documents\"]:\n",
        "        print(source.metadata['source'])"
      ],
      "metadata": {
        "id": "rDkeEPgd3Kn1"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"what is the email ofikram hashmi?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTbnT1bN3LKr",
        "outputId": "929848b3-8c41-4133-b8f9-0d2b3285b018"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-55-3a5493e57c83>:2: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  llm_response = qa_chain(query)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The email of Ikram Hashmi is ikramhashmi1111@gmail.com.\n",
            "\n",
            "\n",
            "Sources:\n",
            "pdfs/Black White Simple Blank Resignation Letter.pdf\n",
            "pdfs/Black White Simple Blank Resignation Letter.pdf\n"
          ]
        }
      ]
    }
  ]
}